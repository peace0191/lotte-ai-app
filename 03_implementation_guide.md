# ğŸ› ï¸ ë¶€ë™ì‚° AI í”Œë«í¼ - ê°œë°œíŒ€ êµ¬í˜„ ê°€ì´ë“œ

> **ëª©ì **: ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ë¥¼ ì‹¤ì œ ì½”ë“œë¡œ êµ¬í˜„í•˜ê¸° ìœ„í•œ ë‹¨ê³„ë³„ ê°€ì´ë“œ  
> **ëŒ€ìƒ**: Backend/ML/DevOps ê°œë°œì

---

## ğŸ“‹ ëª©ì°¨

1. [ê°œë°œ í™˜ê²½ ì„¤ì •](#1-ê°œë°œ-í™˜ê²½-ì„¤ì •)
2. [ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì„¤ê³„](#2-ë°ì´í„°ë² ì´ìŠ¤-ìŠ¤í‚¤ë§ˆ-ì„¤ê³„)
3. [ë°ì´í„° íŒŒì´í”„ë¼ì¸ êµ¬í˜„](#3-ë°ì´í„°-íŒŒì´í”„ë¼ì¸-êµ¬í˜„)
4. [ML ëª¨ë¸ ê°œë°œ ê°€ì´ë“œ](#4-ml-ëª¨ë¸-ê°œë°œ-ê°€ì´ë“œ)
5. [API ì„œë²„ êµ¬í˜„](#5-api-ì„œë²„-êµ¬í˜„)
6. [MLflow ì„¤ì • ë° ìš´ì˜](#6-mlflow-ì„¤ì •-ë°-ìš´ì˜)
7. [ë°°í¬ ë° ì¸í”„ë¼](#7-ë°°í¬-ë°-ì¸í”„ë¼)
8. [ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼](#8-ëª¨ë‹ˆí„°ë§-ë°-ì•Œë¦¼)
9. [í…ŒìŠ¤íŠ¸ ì „ëµ](#9-í…ŒìŠ¤íŠ¸-ì „ëµ)
10. [ë³´ì•ˆ ë° ê·œì • ì¤€ìˆ˜](#10-ë³´ì•ˆ-ë°-ê·œì •-ì¤€ìˆ˜)

---

## 1. ê°œë°œ í™˜ê²½ ì„¤ì •

### 1.1 í•„ìˆ˜ ë„êµ¬ ì„¤ì¹˜

```bash
# Python 3.10 ì´ìƒ
python --version

# ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt
```

### 1.2 requirements.txt

```text
# ML & Data
pandas==2.1.4
numpy==1.26.2
scikit-learn==1.3.2
xgboost==2.0.3
lightgbm==4.1.0
shap==0.44.0

# MLflow
mlflow==2.9.2
boto3==1.34.10  # S3 ì—°ë™

# API
fastapi==0.109.0
uvicorn==0.27.0
pydantic==2.5.3
python-multipart==0.0.6

# Database
psycopg2-binary==2.9.9
sqlalchemy==2.0.25

# Data Pipeline
apache-airflow==2.8.0
requests==2.31.0
beautifulsoup4==4.12.3

# Monitoring
prometheus-client==0.19.0
sentry-sdk==1.39.2

# Utils
python-dotenv==1.0.0
loguru==0.7.2
```

### 1.3 í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```bash
# .env íŒŒì¼
# Database
DATABASE_URL=postgresql://user:password@localhost:5432/realestate_db

# MLflow
MLFLOW_TRACKING_URI=http://localhost:5000
MLFLOW_S3_ENDPOINT_URL=http://localhost:9000
AWS_ACCESS_KEY_ID=minioadmin
AWS_SECRET_ACCESS_KEY=minioadmin

# Redis
REDIS_URL=redis://localhost:6379/0

# API
API_SECRET_KEY=your-secret-key-here
API_CORS_ORIGINS=http://localhost:3000,http://localhost:3001

# External APIs
MOLIT_API_KEY=your-molit-api-key  # êµ­í† ë¶€ API
NAVER_CLIENT_ID=your-naver-client-id
NAVER_CLIENT_SECRET=your-naver-client-secret
```

### 1.4 Docker ê°œë°œ í™˜ê²½

```yaml
# docker-compose.yml
version: '3.8'

services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: realestate_db
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: password123
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  minio:
    image: minio/minio
    command: server /data --console-address ":9001"
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    volumes:
      - minio_data:/data

  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.9.2
    ports:
      - "5000:5000"
    environment:
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin
    command: >
      mlflow server
      --backend-store-uri postgresql://admin:password123@postgres:5432/mlflow_db
      --default-artifact-root s3://mlflow/
      --host 0.0.0.0

volumes:
  postgres_data:
  minio_data:
```

---

## 2. ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì„¤ê³„

### 2.1 ERD (Entity Relationship Diagram)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   properties    â”‚       â”‚   transactions   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)         â”‚â”€â”€â”€â”€â”€â”€<â”‚ property_id (FK) â”‚
â”‚ address         â”‚       â”‚ contract_date    â”‚
â”‚ building_type   â”‚       â”‚ contract_price   â”‚
â”‚ area_sqm        â”‚       â”‚ buyer_id (FK)    â”‚
â”‚ floor           â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ price           â”‚
â”‚ created_at      â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚   user_profiles  â”‚
                          â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚ id (PK)          â”‚
â”‚   features      â”‚       â”‚ age              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤       â”‚ income_range     â”‚
â”‚ id (PK)         â”‚       â”‚ preferred_area   â”‚
â”‚ property_id(FK) â”‚<â”€â”€â”   â”‚ budget_min       â”‚
â”‚ avg_price_3m    â”‚   â”‚   â”‚ budget_max       â”‚
â”‚ price_change_pctâ”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ subway_distance â”‚   â”‚
â”‚ school_score    â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ jeonse_ratio    â”‚   â”‚   â”‚  model_metadata  â”‚
â”‚ updated_at      â”‚   â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚ id (PK)          â”‚
                      â”‚   â”‚ model_name       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚ model_version    â”‚
â”‚  predictions    â”‚   â”‚   â”‚ stage            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚   â”‚ metrics          â”‚
â”‚ id (PK)         â”‚   â”‚   â”‚ created_at       â”‚
â”‚ property_id(FK) â”‚â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ model_version   â”‚
â”‚ undervalued_scoreâ”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ prediction_date â”‚       â”‚   api_logs       â”‚
â”‚ shap_values     â”‚       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚ id (PK)          â”‚
                          â”‚ endpoint         â”‚
                          â”‚ request_data     â”‚
                          â”‚ response_data    â”‚
                          â”‚ latency_ms       â”‚
                          â”‚ timestamp        â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 SQL ìŠ¤í‚¤ë§ˆ ì •ì˜

```sql
-- properties í…Œì´ë¸”
CREATE TABLE properties (
    id SERIAL PRIMARY KEY,
    address VARCHAR(255) NOT NULL,
    building_type VARCHAR(50),  -- 'ì•„íŒŒíŠ¸', 'ì˜¤í”¼ìŠ¤í…”', 'ë¹Œë¼'
    area_sqm DECIMAL(10, 2),
    floor INTEGER,
    price BIGINT,  -- ë§¤ë§¤ê°€ (ë§Œì›)
    jeonse_price BIGINT,  -- ì „ì„¸ê°€ (ë§Œì›)
    latitude DECIMAL(10, 7),
    longitude DECIMAL(10, 7),
    listing_date DATE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_properties_location ON properties(latitude, longitude);
CREATE INDEX idx_properties_price ON properties(price);
CREATE INDEX idx_properties_listing_date ON properties(listing_date);

-- features í…Œì´ë¸” (ML í”¼ì²˜)
CREATE TABLE features (
    id SERIAL PRIMARY KEY,
    property_id INTEGER REFERENCES properties(id),
    avg_price_3m BIGINT,  -- ìµœê·¼ 3ê°œì›” í‰ê·  ê±°ë˜ê°€
    price_change_pct DECIMAL(5, 2),  -- ê°€ê²© ë³€ë™ë¥ 
    subway_distance_m INTEGER,  -- ì§€í•˜ì² ì—­ ê±°ë¦¬
    school_score DECIMAL(3, 1),  -- í•™êµ° ì ìˆ˜ (1-10)
    jeonse_ratio DECIMAL(5, 2),  -- ì „ì„¸ê°€ìœ¨
    crime_rate DECIMAL(5, 2),  -- ë²”ì£„ìœ¨
    population_density INTEGER,  -- ì¸êµ¬ë°€ë„
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(property_id)
);

-- transactions í…Œì´ë¸” (ì‹¤ê±°ë˜ ì´ë ¥)
CREATE TABLE transactions (
    id SERIAL PRIMARY KEY,
    property_id INTEGER REFERENCES properties(id),
    contract_date DATE NOT NULL,
    contract_price BIGINT NOT NULL,
    buyer_id INTEGER REFERENCES user_profiles(id),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_transactions_date ON transactions(contract_date);

-- user_profiles í…Œì´ë¸”
CREATE TABLE user_profiles (
    id SERIAL PRIMARY KEY,
    user_id VARCHAR(100) UNIQUE NOT NULL,
    age INTEGER,
    income_range VARCHAR(50),
    preferred_area VARCHAR(100),
    budget_min BIGINT,
    budget_max BIGINT,
    family_size INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- predictions í…Œì´ë¸” (ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼)
CREATE TABLE predictions (
    id SERIAL PRIMARY KEY,
    property_id INTEGER REFERENCES properties(id),
    model_name VARCHAR(100),
    model_version VARCHAR(50),
    undervalued_score DECIMAL(5, 2),  -- ì €í‰ê°€ ì ìˆ˜ (0-100)
    predicted_price BIGINT,
    shap_values JSONB,  -- SHAP ì„¤ëª…
    prediction_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_predictions_property ON predictions(property_id);
CREATE INDEX idx_predictions_score ON predictions(undervalued_score DESC);

-- model_metadata í…Œì´ë¸” (MLflow Registry ë™ê¸°í™”)
CREATE TABLE model_metadata (
    id SERIAL PRIMARY KEY,
    model_name VARCHAR(100),
    model_version VARCHAR(50),
    stage VARCHAR(20),  -- 'Production', 'Staging', 'Archived'
    metrics JSONB,  -- {'mae': 300, 'rmse': 500, ...}
    registered_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(model_name, model_version)
);

-- api_logs í…Œì´ë¸” (API í˜¸ì¶œ ë¡œê·¸)
CREATE TABLE api_logs (
    id SERIAL PRIMARY KEY,
    endpoint VARCHAR(255),
    method VARCHAR(10),
    request_data JSONB,
    response_data JSONB,
    status_code INTEGER,
    latency_ms INTEGER,
    user_id VARCHAR(100),
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_api_logs_timestamp ON api_logs(timestamp);
CREATE INDEX idx_api_logs_endpoint ON api_logs(endpoint);
```

---

## 3. ë°ì´í„° íŒŒì´í”„ë¼ì¸ êµ¬í˜„

### 3.1 Airflow DAG êµ¬ì¡°

```python
# dags/property_data_pipeline.py
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.utils.dates import days_ago
from datetime import timedelta

default_args = {
    'owner': 'ml-team',
    'depends_on_past': False,
    'email': ['alerts@company.com'],
    'email_on_failure': True,
    'retries': 3,
    'retry_delay': timedelta(minutes=5),
}

dag = DAG(
    'property_data_pipeline',
    default_args=default_args,
    description='ë¶€ë™ì‚° ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬',
    schedule_interval='0 2 * * *',  # ë§¤ì¼ ìƒˆë²½ 2ì‹œ
    start_date=days_ago(1),
    catchup=False,
    tags=['data', 'etl'],
)

# Task 1: ê³µê³µ API ìˆ˜ì§‘
collect_public_data = PythonOperator(
    task_id='collect_public_data',
    python_callable=collect_molit_data,
    dag=dag,
)

# Task 2: í¬ë¡¤ë§
crawl_property_sites = PythonOperator(
    task_id='crawl_property_sites',
    python_callable=crawl_naver_realestate,
    dag=dag,
)

# Task 3: ë°ì´í„° ê²€ì¦
validate_data = PythonOperator(
    task_id='validate_data',
    python_callable=validate_collected_data,
    dag=dag,
)

# Task 4: ì „ì²˜ë¦¬ ë° Feature ìƒì„±
feature_engineering = PythonOperator(
    task_id='feature_engineering',
    python_callable=generate_features,
    dag=dag,
)

# Task 5: DB ì ì¬
load_to_db = PythonOperator(
    task_id='load_to_db',
    python_callable=load_data_to_postgres,
    dag=dag,
)

# Task ì˜ì¡´ì„± ì„¤ì •
[collect_public_data, crawl_property_sites] >> validate_data >> feature_engineering >> load_to_db
```

### 3.2 ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜

```python
# utils/data_collectors.py
import requests
import pandas as pd
from bs4 import BeautifulSoup
from datetime import datetime, timedelta

def collect_molit_data(start_date, end_date):
    """êµ­í† ë¶€ ì‹¤ê±°ë˜ê°€ API ë°ì´í„° ìˆ˜ì§‘"""
    API_KEY = os.getenv('MOLIT_API_KEY')
    BASE_URL = 'http://openapi.molit.go.kr/OpenAPI_ToolInstallPackage/service/rest/RTMSOBJSvc/getRTMSDataSvcAptTradeDev'
    
    results = []
    current_date = start_date
    
    while current_date <= end_date:
        params = {
            'serviceKey': API_KEY,
            'LAWD_CD': '11110',  # ì„œìš¸ ì¢…ë¡œêµ¬ (ì˜ˆì‹œ)
            'DEAL_YMD': current_date.strftime('%Y%m'),
        }
        
        response = requests.get(BASE_URL, params=params)
        if response.status_code == 200:
            # XML íŒŒì‹± ë° ë°ì´í„° ì¶”ì¶œ
            soup = BeautifulSoup(response.content, 'xml')
            items = soup.find_all('item')
            
            for item in items:
                results.append({
                    'address': item.find('ë²•ì •ë™').text + ' ' + item.find('ì•„íŒŒíŠ¸').text,
                    'area_sqm': float(item.find('ì „ìš©ë©´ì ').text),
                    'floor': int(item.find('ì¸µ').text),
                    'price': int(item.find('ê±°ë˜ê¸ˆì•¡').text.replace(',', '')) * 10000,  # ë§Œì› â†’ ì›
                    'contract_date': item.find('ë…„').text + '-' + item.find('ì›”').text + '-' + item.find('ì¼').text,
                })
        
        current_date += timedelta(days=30)
    
    return pd.DataFrame(results)

def crawl_naver_realestate(region='ì„œìš¸'):
    """ë„¤ì´ë²„ ë¶€ë™ì‚° í¬ë¡¤ë§"""
    # ì‹¤ì œ êµ¬í˜„ ì‹œ robots.txt í™•ì¸ ë° ì¤€ìˆ˜
    headers = {'User-Agent': 'Mozilla/5.0'}
    base_url = f'https://land.naver.com/article/articleList.naver?rletTypeCd=A01&tradeTypeCd=A1&location={region}'
    
    response = requests.get(base_url, headers=headers)
    soup = BeautifulSoup(response.content, 'html.parser')
    
    # ì‹¤ì œ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì • í•„ìš”
    properties = []
    for item in soup.select('.item_inner'):
        properties.append({
            'title': item.select_one('.item_title').text,
            'price': item.select_one('.price').text,
            'area': item.select_one('.item_area').text,
        })
    
    return pd.DataFrame(properties)
```

### 3.3 Feature Engineering

```python
# utils/feature_engineering.py
import pandas as pd
import numpy as np
from geopy.distance import geodesic

def generate_features(properties_df, transactions_df):
    """ML ëª¨ë¸ìš© í”¼ì²˜ ìƒì„±"""
    
    features_df = properties_df.copy()
    
    # 1. ì‹œê³„ì—´ í”¼ì²˜
    features_df['avg_price_3m'] = calculate_rolling_avg(transactions_df, window=90)
    features_df['price_change_pct'] = calculate_price_change(transactions_df)
    
    # 2. ì§€ë¦¬ì  í”¼ì²˜
    features_df['subway_distance_m'] = features_df.apply(
        lambda row: nearest_subway_distance(row['latitude'], row['longitude']), 
        axis=1
    )
    
    # 3. ì „ì„¸ê°€ìœ¨
    features_df['jeonse_ratio'] = (features_df['jeonse_price'] / features_df['price']) * 100
    
    # 4. í‰ë‹¹ ê°€ê²©
    features_df['price_per_pyeong'] = features_df['price'] / (features_df['area_sqm'] * 0.3025)
    
    # 5. ì¸µ ë³´ì • (1ì¸µ, ìµœìƒì¸µ í˜ë„í‹°)
    features_df['floor_penalty'] = features_df['floor'].apply(floor_penalty_score)
    
    return features_df

def nearest_subway_distance(lat, lon):
    """ê°€ì¥ ê°€ê¹Œìš´ ì§€í•˜ì² ì—­ ê±°ë¦¬ ê³„ì‚°"""
    # ì§€í•˜ì² ì—­ ì¢Œí‘œ DB (ë¯¸ë¦¬ ì¤€ë¹„)
    SUBWAY_STATIONS = [
        (37.5665, 126.9780),  # ì„œìš¸ì—­
        (37.5547, 126.9707),  # ê°•ë‚¨ì—­
        # ... ë” ë§ì€ ì—­
    ]
    
    property_loc = (lat, lon)
    distances = [geodesic(property_loc, station).meters for station in SUBWAY_STATIONS]
    return min(distances)

def floor_penalty_score(floor):
    """ì¸µë³„ ì„ í˜¸ë„ ì ìˆ˜"""
    if floor == 1:
        return -0.05  # -5% í˜ë„í‹°
    elif floor >= 15:
        return -0.03  # -3% í˜ë„í‹°
    elif 5 <= floor <= 10:
        return 0.03  # +3% í”„ë¦¬ë¯¸ì—„
    else:
        return 0
```

---

## 4. ML ëª¨ë¸ ê°œë°œ ê°€ì´ë“œ

### 4.1 ì €í‰ê°€ ì ìˆ˜ ëª¨ë¸ êµ¬ì¡°

```python
# models/undervalued_model.py
import mlflow
import mlflow.sklearn
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import shap

class UndervaluedScoreModel:
    def __init__(self, experiment_name='undervalued-score'):
        self.experiment_name = experiment_name
        mlflow.set_experiment(experiment_name)
        self.model = None
        
    def train(self, X, y, params=None):
        """ëª¨ë¸ í•™ìŠµ ë° MLflow ë¡œê¹…"""
        
        if params is None:
            params = {
                'n_estimators': 200,
                'learning_rate': 0.05,
                'max_depth': 5,
                'min_samples_split': 20,
                'random_state': 42
            }
        
        # Train/Test ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # MLflow Run ì‹œì‘
        with mlflow.start_run(run_name=f"gb_{datetime.now().strftime('%Y%m%d_%H%M')}"):
            
            # íŒŒë¼ë¯¸í„° ë¡œê¹…
            mlflow.log_params(params)
            
            # ëª¨ë¸ í•™ìŠµ
            self.model = GradientBoostingRegressor(**params)
            self.model.fit(X_train, y_train)
            
            # ì˜ˆì¸¡
            y_pred = self.model.predict(X_test)
            
            # ë©”íŠ¸ë¦­ ê³„ì‚°
            mae = mean_absolute_error(y_test, y_pred)
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))
            r2 = r2_score(y_test, y_pred)
            
            # ë©”íŠ¸ë¦­ ë¡œê¹…
            mlflow.log_metrics({
                'mae': mae,
                'rmse': rmse,
                'r2': r2,
                'mae_millions': mae / 10000,  # ë§Œì› ë‹¨ìœ„ë¡œ ë³€í™˜
            })
            
            # Feature Importance ë¡œê¹…
            feature_importance = pd.DataFrame({
                'feature': X.columns,
                'importance': self.model.feature_importances_
            }).sort_values('importance', ascending=False)
            
            mlflow.log_dict(feature_importance.to_dict(), 'feature_importance.json')
            
            # SHAP ê°’ ê³„ì‚° (ì„¤ëª… ê°€ëŠ¥ì„±)
            explainer = shap.TreeExplainer(self.model)
            shap_values = explainer.shap_values(X_test[:100])  # ìƒ˜í”Œ 100ê°œ
            
            # SHAP plot ì €ì¥
            shap.summary_plot(shap_values, X_test[:100], show=False)
            mlflow.log_figure(plt.gcf(), 'shap_summary.png')
            plt.close()
            
            # ëª¨ë¸ ì €ì¥
            mlflow.sklearn.log_model(
                self.model, 
                'model',
                registered_model_name='undervalued-score-model'
            )
            
            print(f"âœ… Model trained: MAE={mae/10000:.0f}ë§Œì›, RMSE={rmse/10000:.0f}ë§Œì›, RÂ²={r2:.3f}")
            
            return {
                'mae': mae,
                'rmse': rmse,
                'r2': r2,
                'run_id': mlflow.active_run().info.run_id
            }
    
    def calculate_undervalued_score(self, property_features):
        """ì €í‰ê°€ ì ìˆ˜ ê³„ì‚°"""
        predicted_price = self.model.predict(property_features)[0]
        actual_price = property_features['price'].values[0]
        
        # ì €í‰ê°€ìœ¨ ê³„ì‚°
        undervalued_pct = ((predicted_price - actual_price) / predicted_price) * 100
        
        # 0-100 ì ìˆ˜ë¡œ ë³€í™˜
        score = min(max(undervalued_pct * 2, 0), 100)
        
        return {
            'score': score,
            'predicted_price': predicted_price,
            'actual_price': actual_price,
            'undervalued_amount': predicted_price - actual_price
        }
```

### 4.2 ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸

```python
# scripts/train_undervalued_model.py
import pandas as pd
from models.undervalued_model import UndervaluedScoreModel
from utils.data_loaders import load_training_data

def main():
    # 1. ë°ì´í„° ë¡œë“œ
    print("ğŸ“Š Loading training data...")
    X, y = load_training_data()
    
    # 2. ëª¨ë¸ ì´ˆê¸°í™”
    model = UndervaluedScoreModel(experiment_name='undervalued-score-v1')
    
    # 3. í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ
    param_grid = [
        {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3},
        {'n_estimators': 200, 'learning_rate': 0.05, 'max_depth': 5},
        {'n_estimators': 300, 'learning_rate': 0.03, 'max_depth': 7},
    ]
    
    # 4. ì—¬ëŸ¬ ì‹¤í—˜ ì‹¤í–‰
    best_score = float('inf')
    best_run = None
    
    for params in param_grid:
        print(f"\nğŸ”¬ Training with params: {params}")
        results = model.train(X, y, params)
        
        if results['mae'] < best_score:
            best_score = results['mae']
            best_run = results['run_id']
    
    print(f"\nâœ… Best model: Run {best_run}, MAE={best_score/10000:.0f}ë§Œì›")
    
    # 5. Registryì— ë“±ë¡
    client = mlflow.tracking.MlflowClient()
    model_uri = f"runs:/{best_run}/model"
    
    # Stagingìœ¼ë¡œ ë“±ë¡
    result = client.create_model_version(
        name="undervalued-score-model",
        source=model_uri,
        run_id=best_run
    )
    
    print(f"ğŸ“¦ Model registered: version {result.version}")

if __name__ == '__main__':
    main()
```

---

## 5. API ì„œë²„ êµ¬í˜„

### 5.1 FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¡°

```
api/
â”œâ”€â”€ main.py
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ schemas.py
â”‚   â””â”€â”€ ml_models.py
â”œâ”€â”€ routers/
â”‚   â”œâ”€â”€ prediction.py
â”‚   â””â”€â”€ health.py
â”œâ”€â”€ dependencies.py
â””â”€â”€ config.py
```

### 5.2 API ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„

```python
# api/main.py
from fastapi import FastAPI, Depends
from fastapi.middleware.cors import CORSMiddleware
from routers import prediction, health
import mlflow

app = FastAPI(
    title="ë¶€ë™ì‚° AI API",
    description="ì €í‰ê°€ ë§¤ë¬¼ ë°œêµ´ ë° ë§¤ì¹­ API",
    version="1.0.0"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ë¼ìš°í„° ë“±ë¡
app.include_router(prediction.router, prefix="/api/v1", tags=["prediction"])
app.include_router(health.router, prefix="/health", tags=["health"])

@app.on_event("startup")
async def startup_event():
    """ì•± ì‹œì‘ ì‹œ ì‹¤í–‰"""
    # MLflow ëª¨ë¸ ë¡œë“œ
    mlflow.set_tracking_uri(os.getenv('MLFLOW_TRACKING_URI'))
    print("âœ… MLflow connected")

@app.get("/")
async def root():
    return {"message": "ë¶€ë™ì‚° AI API v1.0"}
```

```python
# api/routers/prediction.py
from fastapi import APIRouter, HTTPException, Depends
from pydantic import BaseModel
import mlflow.pyfunc
from typing import List, Dict
import numpy as np

router = APIRouter()

# Production ëª¨ë¸ ë¡œë“œ (ì „ì—­)
model = mlflow.pyfunc.load_model("models:/undervalued-score-model/Production")

class PropertyInput(BaseModel):
    address: str
    building_type: str
    area_sqm: float
    floor: int
    price: int
    jeonse_price: int
    latitude: float
    longitude: float

class UndervaluedResponse(BaseModel):
    score: float
    predicted_price: int
    actual_price: int
    undervalued_amount: int
    explanation: Dict[str, float]
    model_version: str

@router.post("/undervalued-score", response_model=UndervaluedResponse)
async def calculate_undervalued_score(property: PropertyInput):
    """
    ì €í‰ê°€ ì ìˆ˜ ê³„ì‚°
    
    - **score**: 0-100 ì €í‰ê°€ ì ìˆ˜ (ë†’ì„ìˆ˜ë¡ ì €í‰ê°€)
    - **predicted_price**: AI ì˜ˆì¸¡ ì‹œì„¸
    - **actual_price**: ì‹¤ì œ ë§¤ë¬¼ê°€
    - **undervalued_amount**: ì €í‰ê°€ ê¸ˆì•¡ (ì˜ˆì¸¡-ì‹¤ì œ)
    - **explanation**: SHAP ê¸°ë°˜ íŒë‹¨ ê·¼ê±°
    """
    
    try:
        # í”¼ì²˜ ìƒì„±
        features = generate_features(property)
        
        # ì˜ˆì¸¡
        predicted_price = model.predict(features)[0]
        
        # ì €í‰ê°€ ì ìˆ˜ ê³„ì‚°
        undervalued_amount = predicted_price - property.price
        undervalued_pct = (undervalued_amount / predicted_price) * 100
        score = min(max(undervalued_pct * 2, 0), 100)
        
        # SHAP ì„¤ëª… (ê°„ë‹¨í•œ ë²„ì „)
        explanation = {
            'jeonse_ratio': 0.3,  # ì‹¤ì œë¡œëŠ” SHAP ê°’ ê³„ì‚°
            'subway_distance': -0.2,
            'school_score': 0.15,
        }
        
        # API ë¡œê·¸ ì €ì¥ (ë¹„ë™ê¸° ì²˜ë¦¬)
        log_api_call({
            'endpoint': '/undervalued-score',
            'input': property.dict(),
            'output': {'score': score, 'predicted_price': predicted_price}
        })
        
        return UndervaluedResponse(
            score=round(score, 2),
            predicted_price=int(predicted_price),
            actual_price=property.price,
            undervalued_amount=int(undervalued_amount),
            explanation=explanation,
            model_version='v1.2'
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/matching-rank")
async def calculate_matching_rank(
    user_profile: Dict,
    properties: List[PropertyInput]
):
    """
    ì‚¬ìš©ìì™€ ë§¤ë¬¼ ê°„ ë§¤ì¹­ ìˆœìœ„ ê³„ì‚°
    """
    # ë§¤ì¹­ ëª¨ë¸ ë¡œë“œ
    matching_model = mlflow.pyfunc.load_model("models:/matching-model/Production")
    
    # ê° ë§¤ë¬¼ì— ëŒ€í•œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
    results = []
    for prop in properties:
        features = create_matching_features(user_profile, prop)
        match_score = matching_model.predict(features)[0]
        
        results.append({
            'property_id': prop.address,  # ì‹¤ì œë¡œëŠ” ID ì‚¬ìš©
            'match_score': float(match_score),
            'property': prop.dict()
        })
    
    # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
    results = sorted(results, key=lambda x: x['match_score'], reverse=True)
    
    return {'matches': results[:10]}  # ìƒìœ„ 10ê°œ ë°˜í™˜
```

### 5.3 ìºì‹± ë° ì„±ëŠ¥ ìµœì í™”

```python
# api/dependencies.py
from functools import lru_cache
import redis
import json

# Redis ì—°ê²°
redis_client = redis.Redis(host='localhost', port=6379, db=0)

def get_cached_prediction(property_key: str):
    """Redis ìºì‹œì—ì„œ ì˜ˆì¸¡ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°"""
    cached = redis_client.get(f"prediction:{property_key}")
    if cached:
        return json.loads(cached)
    return None

def cache_prediction(property_key: str, result: dict, ttl=3600):
    """ì˜ˆì¸¡ ê²°ê³¼ë¥¼ Redisì— ìºì‹± (1ì‹œê°„ TTL)"""
    redis_client.setex(
        f"prediction:{property_key}",
        ttl,
        json.dumps(result)
    )

@lru_cache(maxsize=100)
def get_model(model_name: str, stage: str = "Production"):
    """ëª¨ë¸ ë¡œë”© ìºì‹±"""
    return mlflow.pyfunc.load_model(f"models:/{model_name}/{stage}")
```

---

## 6. MLflow ì„¤ì • ë° ìš´ì˜

### 6.1 MLflow ì„œë²„ ì„¤ì •

```bash
# MLflow ì„œë²„ ì‹œì‘
mlflow server \
  --backend-store-uri postgresql://admin:password@localhost:5432/mlflow_db \
  --default-artifact-root s3://mlflow-artifacts/ \
  --host 0.0.0.0 \
  --port 5000
```

### 6.2 Model Registry ì‘ì—… ìë™í™”

```python
# scripts/promote_model.py
import mlflow
from mlflow.tracking import MlflowClient

def promote_model_to_production(model_name, version):
    """ëª¨ë¸ì„ Productionìœ¼ë¡œ ìŠ¹ê²©"""
    client = MlflowClient()
    
    # ê¸°ì¡´ Production ëª¨ë¸ì„ Archivedë¡œ
    current_prod = client.get_latest_versions(model_name, stages=["Production"])
    if current_prod:
        client.transition_model_version_stage(
            name=model_name,
            version=current_prod[0].version,
            stage="Archived"
        )
    
    # ìƒˆ ëª¨ë¸ì„ Productionìœ¼ë¡œ
    client.transition_model_version_stage(
        name=model_name,
        version=version,
        stage="Production"
    )
    
    print(f"âœ… Model {model_name} v{version} promoted to Production")

def auto_promote_if_better():
    """ì„±ëŠ¥ì´ ê°œì„ ë˜ë©´ ìë™ ìŠ¹ê²©"""
    client = MlflowClient()
    
    # Staging ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
    staging_models = client.get_latest_versions("undervalued-score-model", stages=["Staging"])
    prod_models = client.get_latest_versions("undervalued-score-model", stages=["Production"])
    
    if not staging_models or not prod_models:
        return
    
    staging_model = staging_models[0]
    prod_model = prod_models[0]
    
    # ë©”íŠ¸ë¦­ ë¹„êµ
    staging_run = client.get_run(staging_model.run_id)
    prod_run = client.get_run(prod_model.run_id)
    
    staging_mae = staging_run.data.metrics['mae']
    prod_mae = prod_run.data.metrics['mae']
    
    # 5% ì´ìƒ ê°œì„ ë˜ë©´ ìŠ¹ê²©
    if staging_mae < prod_mae * 0.95:
        promote_model_to_production("undervalued-score-model", staging_model.version)
```

---

## 7. ë°°í¬ ë° ì¸í”„ë¼

### 7.1 Kubernetes ë°°í¬ ì„¤ì •

```yaml
# k8s/api-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: realestate-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: realestate-api
  template:
    metadata:
      labels:
        app: realestate-api
    spec:
      containers:
      - name: api
        image: realestate-api:latest
        ports:
        - containerPort: 8000
        env:
        - name: MLFLOW_TRACKING_URI
          value: "http://mlflow-service:5000"
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: url
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health/ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: realestate-api-service
spec:
  type: LoadBalancer
  ports:
  - port: 80
    targetPort: 8000
  selector:
    app: realestate-api
```

### 7.2 CI/CD íŒŒì´í”„ë¼ì¸

```yaml
# .github/workflows/deploy.yml
name: Deploy to Production

on:
  push:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install pytest pytest-cov
    
    - name: Run tests
      run: pytest tests/ --cov=./ --cov-report=xml
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3

  build-and-push:
    needs: test
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Build Docker image
      run: docker build -t realestate-api:${{ github.sha }} .
    
    - name: Push to registry
      run: |
        echo ${{ secrets.DOCKER_PASSWORD }} | docker login -u ${{ secrets.DOCKER_USERNAME }} --password-stdin
        docker push realestate-api:${{ github.sha }}

  deploy:
    needs: build-and-push
    runs-on: ubuntu-latest
    steps:
    - name: Deploy to Kubernetes
      run: |
        kubectl set image deployment/realestate-api api=realestate-api:${{ github.sha }}
        kubectl rollout status deployment/realestate-api
```

---

## 8. ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼

### 8.1 Prometheus ë©”íŠ¸ë¦­ ìˆ˜ì§‘

```python
# api/metrics.py
from prometheus_client import Counter, Histogram, Gauge
import time

# ë©”íŠ¸ë¦­ ì •ì˜
REQUEST_COUNT = Counter(
    'api_requests_total', 
    'Total API requests',
    ['endpoint', 'method', 'status']
)

REQUEST_LATENCY = Histogram(
    'api_request_duration_seconds',
    'API request latency',
    ['endpoint']
)

MODEL_PREDICTION_COUNT = Counter(
    'model_predictions_total',
    'Total model predictions',
    ['model_name', 'model_version']
)

ACTIVE_MODELS = Gauge(
    'active_models',
    'Number of active models',
    ['stage']
)

# ë¯¸ë“¤ì›¨ì–´ì—ì„œ ì‚¬ìš©
@app.middleware("http")
async def monitor_requests(request: Request, call_next):
    start_time = time.time()
    
    response = await call_next(request)
    
    duration = time.time() - start_time
    REQUEST_COUNT.labels(
        endpoint=request.url.path,
        method=request.method,
        status=response.status_code
    ).inc()
    
    REQUEST_LATENCY.labels(
        endpoint=request.url.path
    ).observe(duration)
    
    return response
```

### 8.2 Grafana ëŒ€ì‹œë³´ë“œ ì„¤ì •

```json
{
  "dashboard": {
    "title": "ë¶€ë™ì‚° AI ëª¨ë‹ˆí„°ë§",
    "panels": [
      {
        "title": "API ìš”ì²­ ìˆ˜",
        "targets": [{
          "expr": "rate(api_requests_total[5m])"
        }]
      },
      {
        "title": "í‰ê·  ì‘ë‹µ ì‹œê°„",
        "targets": [{
          "expr": "histogram_quantile(0.95, api_request_duration_seconds_bucket)"
        }]
      },
      {
        "title": "ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜",
        "targets": [{
          "expr": "rate(model_predictions_total[5m])"
        }]
      }
    ]
  }
}
```

---

## 9. í…ŒìŠ¤íŠ¸ ì „ëµ

### 9.1 ìœ ë‹› í…ŒìŠ¤íŠ¸

```python
# tests/test_models.py
import pytest
import pandas as pd
from models.undervalued_model import UndervaluedScoreModel

def test_model_prediction():
    """ëª¨ë¸ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸"""
    model = UndervaluedScoreModel()
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    X = pd.DataFrame({
        'area_sqm': [84.5],
        'floor': [10],
        'subway_distance_m': [500],
        'jeonse_ratio': [65.0],
    })
    
    # ì˜ˆì¸¡ (ëª¨ë¸ì´ í•™ìŠµë˜ì–´ ìˆë‹¤ê³  ê°€ì •)
    result = model.calculate_undervalued_score(X)
    
    assert 0 <= result['score'] <= 100
    assert result['predicted_price'] > 0

def test_feature_engineering():
    """í”¼ì²˜ ìƒì„± í…ŒìŠ¤íŠ¸"""
    from utils.feature_engineering import generate_features
    
    properties_df = pd.DataFrame({
        'price': [50000],
        'jeonse_price': [35000],
        'area_sqm': [84.5],
    })
    
    features = generate_features(properties_df, None)
    
    assert 'jeonse_ratio' in features.columns
    assert features['jeonse_ratio'].iloc[0] == 70.0
```

### 9.2 í†µí•© í…ŒìŠ¤íŠ¸

```python
# tests/test_api.py
from fastapi.testclient import TestClient
from api.main import app

client = TestClient(app)

def test_undervalued_score_endpoint():
    """API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸"""
    payload = {
        "address": "ì„œìš¸ì‹œ ê°•ë‚¨êµ¬ ì—­ì‚¼ë™",
        "building_type": "ì•„íŒŒíŠ¸",
        "area_sqm": 84.5,
        "floor": 10,
        "price": 100000,
        "jeonse_price": 70000,
        "latitude": 37.5665,
        "longitude": 126.9780
    }
    
    response = client.post("/api/v1/undervalued-score", json=payload)
    
    assert response.status_code == 200
    data = response.json()
    assert 'score' in data
    assert 0 <= data['score'] <= 100
```

---

## 10. ë³´ì•ˆ ë° ê·œì • ì¤€ìˆ˜

### 10.1 API ì¸ì¦

```python
# api/auth.py
from fastapi import Security, HTTPException
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
import jwt

security = HTTPBearer()

def verify_token(credentials: HTTPAuthorizationCredentials = Security(security)):
    """JWT í† í° ê²€ì¦"""
    token = credentials.credentials
    
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=["HS256"])
        return payload
    except jwt.ExpiredSignatureError:
        raise HTTPException(status_code=401, detail="Token expired")
    except jwt.InvalidTokenError:
        raise HTTPException(status_code=401, detail="Invalid token")

# ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ì‚¬ìš©
@router.post("/undervalued-score")
async def calculate_score(
    property: PropertyInput,
    user = Depends(verify_token)
):
    # ...
```

### 10.2 ê°œì¸ì •ë³´ ë³´í˜¸

```python
# utils/privacy.py
from cryptography.fernet import Fernet

# ì•”í˜¸í™” í‚¤ (í™˜ê²½ ë³€ìˆ˜ë¡œ ê´€ë¦¬)
cipher = Fernet(os.getenv('ENCRYPTION_KEY'))

def encrypt_sensitive_data(data: str) -> str:
    """ë¯¼ê° ë°ì´í„° ì•”í˜¸í™”"""
    return cipher.encrypt(data.encode()).decode()

def decrypt_sensitive_data(encrypted: str) -> str:
    """ì•”í˜¸í™”ëœ ë°ì´í„° ë³µí˜¸í™”"""
    return cipher.decrypt(encrypted.encode()).decode()

# ì‚¬ìš© ì˜ˆì‹œ
user_phone = encrypt_sensitive_data("010-1234-5678")
```

---

## ë§ˆë¬´ë¦¬

### âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

êµ¬í˜„ ì „ì— ë‹¤ìŒ ì‚¬í•­ì„ í™•ì¸í•˜ì„¸ìš”:

- [ ] ê°œë°œ í™˜ê²½ ì„¤ì • ì™„ë£Œ (Python, Docker, Postgres)
- [ ] MLflow ì„œë²„ ì‹¤í–‰ í™•ì¸
- [ ] ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ìƒì„±
- [ ] ìƒ˜í”Œ ë°ì´í„° ì¤€ë¹„
- [ ] ì²« ë²ˆì§¸ ëª¨ë¸ í•™ìŠµ ì„±ê³µ
- [ ] API ì„œë²„ ë¡œì»¬ ì‹¤í–‰ í™•ì¸
- [ ] í…ŒìŠ¤íŠ¸ ì½”ë“œ ì‘ì„± ë° í†µê³¼
- [ ] ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ì„¤ì •

### ğŸ“š ì¶”ê°€ í•™ìŠµ ìë£Œ

- [MLflow ê³µì‹ ë¬¸ì„œ](https://mlflow.org/docs/latest/index.html)
- [FastAPI íŠœí† ë¦¬ì–¼](https://fastapi.tiangolo.com/tutorial/)
- [Kubernetes ê¸°ì´ˆ](https://kubernetes.io/docs/tutorials/)
- [SHAP ì„¤ëª… ê°€ëŠ¥ AI](https://shap.readthedocs.io/)

---

**ë¬¸ì„œ ë²„ì „**: v1.0  
**ìµœì¢… ìˆ˜ì •**: 2026.02.06  
**ì‘ì„±ì**: ML Engineering Team
