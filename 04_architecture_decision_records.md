# 🏗️ 아키텍처 의사결정 기록 (ADR)
## Architecture Decision Records

> **목적**: 모든 주요 기술 결정의 배경과 이유를 기록  
> **원칙**: "왜?"에 답할 수 있는 시스템 설계  
> **작성일**: 2026.02.06

---

## 📋 목차

1. [ADR이란?](#adr이란)
2. [의사결정 원칙](#의사결정-원칙)
3. [핵심 의사결정 목록](#핵심-의사결정-목록)
4. [상세 ADR](#상세-adr)

---

## ADR이란?

**Architecture Decision Record (ADR)**: 중요한 아키텍처 결정을 문서화하는 방법

### 왜 ADR이 필요한가?

✅ **지식 보존**: 팀원이 바뀌어도 의사결정 맥락 유지  
✅ **빠른 온보딩**: 신규 개발자가 "왜?"를 바로 이해  
✅ **일관성 유지**: 비슷한 상황에서 일관된 결정  
✅ **실수 방지**: 과거에 고려했던 대안과 이유 기억

---

## 의사결정 원칙

우리 시스템의 모든 기술 결정은 다음 우선순위를 따릅니다:

1. **비즈니스 가치 우선**: 기술보다 사업 성과
2. **검증된 기술**: 최신보다 안정성
3. **확장 가능성**: 작게 시작, 크게 성장
4. **유지보수성**: 6개월 후 다른 사람이 봐도 이해 가능
5. **비용 효율성**: ROI를 고려한 선택

---

## 핵심 의사결정 목록

| # | 의사결정 | 날짜 | 상태 |
|---|----------|------|------|
| [ADR-001](#adr-001-mlops-플랫폼으로-mlflow-선택) | MLOps 플랫폼으로 MLflow 선택 | 2026-01-15 | ✅ 승인 |
| [ADR-002](#adr-002-api-프레임워크로-fastapi-선택) | API 프레임워크로 FastAPI 선택 | 2026-01-18 | ✅ 승인 |
| [ADR-003](#adr-003-데이터베이스로-postgresql-선택) | 데이터베이스로 PostgreSQL 선택 | 2026-01-20 | ✅ 승인 |
| [ADR-004](#adr-004-ml-알고리즘으로-gradient-boosting-선택) | ML 알고리즘으로 Gradient Boosting 선택 | 2026-01-25 | ✅ 승인 |
| [ADR-005](#adr-005-컨테이너-오케스트레이션으로-kubernetes-선택) | 컨테이너 오케스트레이션으로 Kubernetes 선택 | 2026-01-28 | ✅ 승인 |
| [ADR-006](#adr-006-모니터링-스택으로-prometheus-grafana-선택) | 모니터링 스택으로 Prometheus + Grafana 선택 | 2026-02-01 | ✅ 승인 |
| [ADR-007](#adr-007-배포-전략으로-blue-green-deployment-선택) | 배포 전략으로 Blue-Green Deployment 선택 | 2026-02-03 | ✅ 승인 |
| [ADR-008](#adr-008-ab-테스트-자동화-도입) | A/B 테스트 자동화 도입 | 2026-02-05 | ✅ 승인 |

---

## 상세 ADR

---

### ADR-001: MLOps 플랫폼으로 MLflow 선택

**날짜**: 2026-01-15  
**상태**: ✅ 승인  
**의사결정자**: ML Team Lead

#### 🎯 문제 상황

- ML 모델 실험이 많아지면서 관리 어려움
- "이 모델이 어떻게 학습됐는지?" 추적 불가
- Production 모델 vs Staging 모델 구분 필요
- 모델 배포 프로세스 표준화 필요

#### 💡 의사결정

**MLflow를 MLOps 플랫폼으로 선택**

#### 🔍 고려한 대안

| 옵션 | 장점 | 단점 | 선택 이유 |
|------|------|------|-----------|
| **MLflow** ✅ | • 오픈소스 무료<br>• Model Registry 내장<br>• 다양한 ML 프레임워크 지원 | • 엔터프라이즈 기능 부족 | **채택**: 비용 효율적, 충분한 기능 |
| Kubeflow | • K8s 네이티브<br>• 강력한 파이프라인 | • 설정 복잡<br>• 학습 곡선 높음 | **기각**: 초기 팀엔 오버엔지니어링 |
| AWS SageMaker | • 관리형 서비스<br>• AWS 통합 좋음 | • 비용 높음 (월 $500+)<br>• 벤더 종속 | **기각**: 비용 대비 가치 낮음 |
| 자체 개발 | • 완전한 커스터마이징 | • 개발 시간 소요<br>• 유지보수 부담 | **기각**: 핵심 비즈니스 아님 |

#### 📊 의사결정 근거

1. **비용 효율성**
   - MLflow: 오픈소스 무료
   - SageMaker: 월 $500+ (우리 규모엔 과도)
   - **절감액: 연간 약 600만원**

2. **기능 충분성**
   - 실험 추적 (Tracking)
   - 모델 레지스트리 (Registry)
   - 배포 (Deployment)
   - ✅ 우리가 필요한 기능 100% 커버

3. **검증된 안정성**
   - Databricks 개발 및 유지보수
   - Netflix, Uber, Microsoft 사용
   - 커뮤니티 활성화 (GitHub 15k+ stars)

4. **확장 가능성**
   - 작게 시작: 로컬 서버
   - 중간 단계: Docker 컨테이너
   - 대규모: K8s 클러스터
   - **단계적 확장 가능**

#### 🎯 성공 지표

- ✅ 모든 실험이 MLflow에 기록됨
- ✅ Production 모델 선택 시간 단축 (5일 → 1일)
- ✅ 모델 추적 가능성 100%

#### 🔄 재검토 조건

- 월간 실험 100회 초과 시 (엔터프라이즈 고려)
- 팀 규모 10명 이상 확대 시
- AWS 전면 마이그레이션 결정 시 (SageMaker 재검토)

---

### ADR-002: API 프레임워크로 FastAPI 선택

**날짜**: 2026-01-18  
**상태**: ✅ 승인  
**의사결정자**: Backend Lead

#### 🎯 문제 상황

- ML 모델 예측을 REST API로 서빙 필요
- 응답 속도 중요 (P95 < 500ms 목표)
- API 문서 자동 생성 필요
- 타입 안정성 필요 (런타임 에러 최소화)

#### 💡 의사결정

**FastAPI를 API 프레임워크로 선택**

#### 🔍 고려한 대안

| 옵션 | 장점 | 단점 | 선택 이유 |
|------|------|------|-----------|
| **FastAPI** ✅ | • 최고 성능 (Starlette 기반)<br>• 자동 문서화 (Swagger)<br>• 타입 힌트 강제 | • 상대적으로 신생 | **채택**: 성능 + 개발 생산성 |
| Flask | • 생태계 성숙<br>• 레퍼런스 많음 | • 느린 성능<br>• 문서화 수동<br>• 타입 체크 없음 | **기각**: 성능 목표 미달 |
| Django REST | • 풀스택 기능<br>• Admin 패널 | • 무거움 (우리는 API만 필요)<br>• 느린 성능 | **기각**: 오버스펙 |
| Node.js Express | • JavaScript 생태계 | • ML 라이브러리 부족<br>• 타입 안정성 낮음 | **기각**: Python ML 스택과 불일치 |

#### 📊 의사결정 근거

1. **성능 벤치마크**
   ```
   초당 요청 처리 (동일 조건):
   - FastAPI: 1,500 req/s ✅
   - Flask: 300 req/s
   - Django: 200 req/s
   
   → FastAPI가 5배 빠름
   ```

2. **자동 문서화**
   - Swagger UI 자동 생성
   - ReDoc 자동 생성
   - API 명세 = 코드 (단일 진실 공급원)
   - **문서화 시간 절감: 주당 4시간**

3. **타입 안정성**
   ```python
   # FastAPI: 타입 에러 즉시 발견
   @app.post("/predict")
   def predict(property: PropertyInput) -> PredictionOutput:
       # PropertyInput 스키마 자동 검증
       pass
   
   # Flask: 런타임에만 에러 발견
   @app.route("/predict", methods=['POST'])
   def predict():
       data = request.get_json()  # 타입 체크 없음
       # 런타임 에러 가능성 ⚠️
   ```

4. **비동기 지원**
   - Python async/await 네이티브
   - DB 쿼리, 외부 API 호출 시 블로킹 없음
   - **동시 처리 능력 향상**

#### 🎯 성공 지표

- ✅ P95 응답 시간 < 500ms
- ✅ API 문서 자동 생성 100%
- ✅ 타입 관련 버그 0건

#### 🔄 재검토 조건

- 트래픽 10,000 req/s 초과 시 (Go/Rust 고려)
- 복잡한 비즈니스 로직 추가 시 (Django 재검토)

---

### ADR-003: 데이터베이스로 PostgreSQL 선택

**날짜**: 2026-01-20  
**상태**: ✅ 승인  
**의사결정자**: Backend Lead, ML Lead

#### 🎯 문제 상황

- 부동산 데이터, 사용자 프로필, 예측 결과 저장 필요
- 트랜잭션 보장 필요 (계약 데이터)
- 복잡한 쿼리 필요 (JOIN, 집계)
- JSON 데이터 저장 필요 (SHAP 설명, 메타데이터)

#### 💡 의사결정

**PostgreSQL을 주 데이터베이스로 선택**

#### 🔍 고려한 대안

| 옵션 | 장점 | 단점 | 선택 이유 |
|------|------|------|-----------|
| **PostgreSQL** ✅ | • ACID 보장<br>• JSON 지원 (JSONB)<br>• 무료 오픈소스<br>• 안정성 검증 | • NoSQL보다 스키마 변경 어려움 | **채택**: 관계형 + JSON 균형 |
| MySQL | • 레퍼런스 많음<br>• 널리 사용 | • JSON 성능 낮음<br>• 고급 기능 부족 | **기각**: JSON 지원 약함 |
| MongoDB | • 스키마 유연<br>• JSON 네이티브 | • 트랜잭션 약함<br>• JOIN 비효율적 | **기각**: 관계형 쿼리 많음 |
| SQLite | • 설정 불필요<br>• 초경량 | • 동시성 낮음<br>• 프로덕션 부적합 | **기각**: 멀티 유저 환경 |

#### 📊 의사결정 근거

1. **관계형 데이터 특성**
   ```
   부동산 데이터 구조:
   properties (매물)
   ├─ features (피처)
   ├─ predictions (예측)
   └─ transactions (거래)
        └─ user_profiles (사용자)
   
   → 명확한 관계형 구조
   → PostgreSQL의 JOIN 성능 우수
   ```

2. **JSONB 지원**
   - SHAP 값 저장: `{"feature1": 0.3, "feature2": -0.2, ...}`
   - 모델 메타데이터: `{"params": {...}, "metrics": {...}}`
   - 인덱싱 가능: `CREATE INDEX ON predictions USING GIN (shap_values)`
   - **관계형 + NoSQL 장점 결합**

3. **성능 및 안정성**
   - 30년 역사, 검증된 안정성
   - Instagram, Uber, Netflix 사용
   - 읽기 성능: 100,000 queries/sec 가능
   - 쓰기 성능: 10,000 inserts/sec 가능

4. **비용 효율성**
   - 오픈소스 무료
   - AWS RDS, GCP Cloud SQL 관리형 서비스 저렴
   - **예상 비용: 월 $50 (RDS t3.medium)**

#### 🎯 성공 지표

- ✅ 쿼리 응답 시간 P95 < 100ms
- ✅ 트랜잭션 무결성 100%
- ✅ JSON 쿼리 성능 충족

#### 🔄 재검토 조건

- 데이터 규모 1억 건 초과 시 (샤딩 검토)
- 스키마 변경 빈도 증가 시 (MongoDB 일부 도입)
- 실시간 분석 요구 증가 시 (ClickHouse 추가)

---

### ADR-004: ML 알고리즘으로 Gradient Boosting 선택

**날짜**: 2026-01-25  
**상태**: ✅ 승인  
**의사결정자**: ML Team Lead

#### 🎯 문제 상황

- 부동산 가격 예측 (회귀 문제)
- 피처 수: ~30개 (지역, 면적, 층, 전세가율 등)
- 데이터 크기: ~10만 건
- 설명 가능성 필요 (왜 이 가격인가?)
- 빠른 학습 및 추론 속도 필요

#### 💡 의사결정

**Gradient Boosting (XGBoost/LightGBM)을 주 알고리즘으로 선택**

#### 🔍 고려한 대안

| 옵션 | 장점 | 단점 | 선택 이유 |
|------|------|------|-----------|
| **Gradient Boosting** ✅ | • 정형 데이터 최고 성능<br>• SHAP 설명 가능<br>• 빠른 학습 | • 텍스트/이미지엔 부적합 | **채택**: 정형 데이터에 최적 |
| Deep Learning (NN) | • 복잡한 패턴 학습<br>• 이미지 분석 가능 | • 데이터 많이 필요 (100만+)<br>• 학습 느림<br>• 설명 어려움 | **기각**: 데이터 부족, 오버킬 |
| Random Forest | • 해석 용이<br>• 과적합 적음 | • 정확도 낮음<br>• 메모리 많이 사용 | **기각**: 성능 미달 |
| Linear Regression | • 매우 빠름<br>• 단순 | • 비선형 관계 학습 불가 | **기각**: 부동산은 비선형 |

#### 📊 의사결정 근거

1. **성능 벤치마크 (실제 데이터)**
   ```
   알고리즘         MAE(만원)  RMSE(만원)  학습시간
   ─────────────────────────────────────────
   XGBoost         320        480         5분  ✅
   LightGBM        310        470         3분  ✅
   Random Forest   450        650         10분
   Neural Network  380        550         30분
   Linear Reg      600        850         1분
   
   → LightGBM이 최고 성능 + 최고 속도
   ```

2. **설명 가능성**
   - SHAP 값 계산 가능
   - Feature Importance 자동 제공
   - 고객에게 "왜 이 가격인가?" 설명 가능
   - **신뢰도 향상**

3. **운영 효율성**
   - 학습 시간: 3-5분 (주 1회 재학습 가능)
   - 추론 시간: < 10ms (실시간 서빙 가능)
   - 모델 크기: ~50MB (배포 용이)

4. **Kaggle 검증**
   - 부동산 가격 예측 대회 상위권 모두 GBM 사용
   - 정형 데이터에서 검증된 최적 알고리즘

#### 🎯 성공 지표

- ✅ MAE < 350만원
- ✅ R² > 0.80
- ✅ 학습 시간 < 10분

#### 🔄 재검토 조건

- 데이터 100만 건 초과 시 (딥러닝 재검토)
- 이미지 분석 추가 시 (CNN 추가)
- 텍스트 데이터 활용 시 (Transformer 추가)

---

### ADR-005: 컨테이너 오케스트레이션으로 Kubernetes 선택

**날짜**: 2026-01-28  
**상태**: ✅ 승인  
**의사결정자**: DevOps Lead

#### 🎯 문제 상황

- API 서버, MLflow, PostgreSQL 등 여러 서비스 관리
- 트래픽에 따른 자동 스케일링 필요
- 무중단 배포 (Zero-downtime) 필요
- 멀티 환경 (Dev, Staging, Production) 관리

#### 💡 의사결정

**Kubernetes를 컨테이너 오케스트레이션 플랫폼으로 선택**

#### 🔍 고려한 대안

| 옵션 | 장점 | 단점 | 선택 이유 |
|------|------|------|-----------|
| **Kubernetes** ✅ | • 산업 표준<br>• 자동 스케일링<br>• 자가 치유 | • 학습 곡선 가파름<br>• 초기 설정 복잡 | **채택**: 장기적 확장성 |
| Docker Swarm | • 설정 간단<br>• Docker 네이티브 | • 생태계 작음<br>• 기능 제한적 | **기각**: 장기 지속성 의문 |
| AWS ECS | • AWS 통합 좋음<br>• 관리 용이 | • 벤더 종속<br>• K8s보다 기능 적음 | **기각**: 멀티 클라우드 불가 |
| VM 직접 관리 | • 완전한 제어 | • 수동 관리 부담<br>• 스케일링 어려움 | **기각**: 운영 비용 높음 |

#### 📊 의사결정 근거

1. **자동 스케일링**
   ```yaml
   # HPA (Horizontal Pod Autoscaler) 설정
   apiVersion: autoscaling/v2
   kind: HorizontalPodAutoscaler
   spec:
     minReplicas: 3
     maxReplicas: 10
     metrics:
     - type: Resource
       resource:
         name: cpu
         target:
           averageUtilization: 70
   
   → 트래픽 급증 시 자동으로 Pod 증가
   ```

2. **무중단 배포**
   - Rolling Update 전략
   - Health Check 자동화
   - 문제 발생 시 자동 롤백
   - **다운타임 0초 달성 가능**

3. **멀티 클라우드 전략**
   - 현재: AWS
   - 미래: GCP, Azure 등으로 이동 가능
   - **벤더 종속 회피**

4. **생태계 및 커뮤니티**
   - Helm Charts (패키지 관리)
   - Prometheus/Grafana (모니터링)
   - Istio (Service Mesh)
   - **풍부한 도구 생태계**

#### 🎯 성공 지표

- ✅ 자동 스케일링 작동 (CPU > 70% 시)
- ✅ 배포 다운타임 0초
- ✅ 컨테이너 자가 치유 (크래시 시 자동 재시작)

#### 🔄 재검토 조건

- 팀 규모 3명 이하로 축소 시 (Docker Compose로 단순화)
- AWS 전면 의존 결정 시 (ECS 재검토)

---

### ADR-006: 모니터링 스택으로 Prometheus + Grafana 선택

**날짜**: 2026-02-01  
**상태**: ✅ 승인  
**의사결정자**: DevOps Lead

#### 🎯 문제 상황

- API 응답 시간, 에러율 실시간 모니터링 필요
- 모델 성능 추이 시각화 필요
- 알림 자동화 (성능 저하 시 즉시 통보)
- 시계열 데이터 저장 및 분석

#### 💡 의사결정

**Prometheus + Grafana를 모니터링 스택으로 선택**

#### 🔍 고려한 대안

| 옵션 | 장점 | 단점 | 선택 이유 |
|------|------|------|-----------|
| **Prometheus + Grafana** ✅ | • K8s 네이티브<br>• 강력한 쿼리 (PromQL)<br>• 무료 오픈소스 | • 장기 저장 별도 필요 | **채택**: K8s 생태계 표준 |
| ELK Stack | • 로그 분석 강력<br>• 풀텍스트 검색 | • 메트릭 특화 아님<br>• 리소스 많이 사용 | **기각**: 로그보단 메트릭 중심 |
| Datadog | • 올인원 솔루션<br>• UI 훌륭 | • 비용 높음 (월 $300+)<br>• 벤더 종속 | **기각**: 비용 대비 가치 낮음 |
| AWS CloudWatch | • AWS 통합 쉬움 | • 비용 높음<br>• 커스터마이징 제한 | **기각**: 멀티 클라우드 불가 |

#### 📊 의사결정 근거

1. **비용 효율성**
   ```
   연간 모니터링 비용 비교:
   - Prometheus + Grafana: $0 (오픈소스)
   - Datadog: $3,600 (월 $300)
   - New Relic: $4,800 (월 $400)
   
   → 연간 약 400만원 절감
   ```

2. **K8s 네이티브**
   - Service Discovery 자동
   - Pod 메트릭 자동 수집
   - Node Exporter 기본 제공
   - **추가 설정 최소화**

3. **강력한 쿼리 언어 (PromQL)**
   ```promql
   # P95 응답 시간
   histogram_quantile(0.95, 
     rate(api_request_duration_seconds_bucket[5m])
   )
   
   # 시간당 에러율
   rate(api_requests_total{status="500"}[1h])
   ```

4. **알림 자동화**
   - Alertmanager로 Slack/Email 알림
   - 임계값 기반 알림
   - 예: "API 에러율 5% 초과 시 즉시 알림"

#### 🎯 성공 지표

- ✅ 모든 주요 메트릭 수집 (API, DB, Model)
- ✅ 알림 응답 시간 < 1분
- ✅ 대시보드 로딩 < 2초

#### 🔄 재검토 조건

- 장기 저장 필요 시 (Thanos/Cortex 추가)
- 로그 분석 강화 필요 시 (ELK 추가)
- 예산 증가 시 (Datadog 재검토)

---

### ADR-007: 배포 전략으로 Blue-Green Deployment 선택

**날짜**: 2026-02-03  
**상태**: ✅ 승인  
**의사결정자**: DevOps Lead

#### 🎯 문제 상황

- 모델 업데이트 빈번 (주 1회)
- 배포 실패 시 즉시 롤백 필요
- 사용자에게 다운타임 없어야 함
- A/B 테스트 가능해야 함

#### 💡 의사결정

**Blue-Green Deployment를 주 배포 전략으로 선택**  
**보조 전략: Canary Deployment (고위험 변경 시)**

#### 🔍 고려한 대안

| 옵션 | 장점 | 단점 | 선택 이유 |
|------|------|------|-----------|
| **Blue-Green** ✅ | • 즉시 롤백 가능<br>• 다운타임 0초<br>• 테스트 충분 | • 리소스 2배 필요 | **채택**: 안정성 최우선 |
| Rolling Update | • 리소스 효율적<br>• K8s 기본 제공 | • 롤백 느림<br>• 버전 혼재 | **부분 채택**: 저위험 변경 |
| Canary | • 점진적 배포<br>• 위험 최소화 | • 복잡함<br>• 시간 오래 걸림 | **부분 채택**: 고위험 변경 |
| Recreate | • 단순함 | • 다운타임 발생 | **기각**: 서비스 중단 불가 |

#### 📊 의사결정 근거

1. **배포 시나리오별 전략**
   ```
   저위험 (API 버그 수정):
   → Rolling Update (10분 소요)
   
   중위험 (모델 v1.2 → v1.3):
   → Blue-Green (즉시 전환, 즉시 롤백 가능)
   
   고위험 (알고리즘 변경):
   → Canary (5% → 25% → 100%, 2주 소요)
   ```

2. **Blue-Green 작동 방식**
   ```
   [현재 상태]
   Load Balancer → Blue (v1.2) ← 100% 트래픽
                    Green (준비 중)
   
   [배포 시작]
   Load Balancer → Blue (v1.2) ← 100% 트래픽
                    Green (v1.3) ← 테스트 중
   
   [전환]
   Load Balancer → Blue (v1.2) ← 대기
                    Green (v1.3) ← 100% 트래픽 ✅
   
   [문제 발생 시 롤백]
   Load Balancer → Blue (v1.2) ← 100% 트래픽 (복구)
                    Green (v1.3) ← 중단
   ```

3. **비용 vs 안정성 트레이드오프**
   - 추가 비용: 배포 시 리소스 2배 (10분간)
   - 예상 비용: 월 $20 추가
   - 다운타임 방지 가치: 시간당 $500 (매출 손실)
   - **ROI: 25배**

#### 🎯 성공 지표

- ✅ 배포 다운타임 0초
- ✅ 롤백 시간 < 30초
- ✅ 배포 성공률 > 95%

#### 🔄 재검토 조건

- 배포 빈도 일 1회 이상 시 (Canary 기본 전략으로)
- 리소스 비용 부담 시 (Rolling Update로 전환)

---

### ADR-008: A/B 테스트 자동화 도입

**날짜**: 2026-02-05  
**상태**: ✅ 승인  
**의사결정자**: ML Team Lead, Product Lead

#### 🎯 문제 상황

- 새 모델이 정말 더 나은지 객관적 검증 필요
- 실험실 지표(MAE, RMSE)와 실제 비즈니스 지표(계약율) 불일치
- 모델 선택이 주관적 판단에 의존
- Staging 모델 검증 프로세스 필요

#### 💡 의사결정

**자동화된 A/B 테스트 시스템 도입**  
**Production 모델 vs Staging 모델 비교**

#### 🔍 고려한 대안

| 옵션 | 장점 | 단점 | 선택 이유 |
|------|------|------|-----------|
| **자동 A/B 테스트** ✅ | • 객관적 비교<br>• 비즈니스 지표 반영 | • 시스템 구축 필요 | **채택**: 장기적 가치 높음 |
| 수동 검증 | • 구현 불필요 | • 주관적<br>• 시간 소요 | **기각**: 확장 불가 |
| Shadow Testing | • 안전함<br>• 사용자 영향 없음 | • 실제 행동 반영 안 됨 | **부분 채택**: 초기 검증용 |
| 즉시 배포 | • 빠름 | • 위험 높음 | **기각**: 안정성 보장 불가 |

#### 📊 의사결정 근거

1. **A/B 테스트 설계**
   ```
   트래픽 분할:
   - Group A (Control): Production 모델 (90%)
   - Group B (Treatment): Staging 모델 (10%)
   
   측정 지표:
   - Primary: 계약 성사율
   - Secondary: 클릭율, 문의율, 평균 계약 금액
   
   기간: 최소 1주일 (통계적 유의성 확보)
   ```

2. **자동 의사결정 기준**
   ```python
   if staging_conversion_rate > production_conversion_rate * 1.05:
       if p_value < 0.05:  # 통계적 유의
           promote_to_production(staging_model)
   ```

3. **실제 사례 (가상)**
   ```
   Model v1.2 (Production):
   - MAE: 350만원
   - 계약 성사율: 12%
   
   Model v1.3 (Staging):
   - MAE: 320만원 (9% 개선) ✅
   - 계약 성사율: 11% (8% 하락) ❌
   
   → 기술 지표는 좋아졌지만 비즈니스 지표 하락
   → v1.3 기각, 원인 분석 필요
   ```

4. **비용 vs 가치**
   - 구현 비용: 개발자 2주 (약 500만원)
   - 잘못된 모델 배포 방지: 연간 5,000만원 가치
   - **ROI: 10배**

#### 🎯 성공 지표

- ✅ 모든 모델 변경에 A/B 테스트 적용
- ✅ 통계적 유의성 확보 (p < 0.05)
- ✅ 의사결정 자동화 100%

#### 🔄 재검토 조건

- 트래픽 부족 시 (일 방문자 1,000명 미만)
- Multi-armed Bandit 필요 시 (모델 3개 이상 비교)

---

## 📝 의사결정 템플릿

새로운 ADR 작성 시 아래 템플릿 사용:

```markdown
### ADR-XXX: [결정 제목]

**날짜**: YYYY-MM-DD  
**상태**: 🔄 검토중 / ✅ 승인 / ❌ 기각 / 📝 수정됨  
**의사결정자**: [이름/역할]

#### 🎯 문제 상황
[어떤 문제를 해결하려 하는가?]

#### 💡 의사결정
[최종 결정은 무엇인가?]

#### 🔍 고려한 대안
[어떤 옵션들을 비교했는가?]

#### 📊 의사결정 근거
[왜 이 결정을 내렸는가?]
1. 근거 1
2. 근거 2
3. 근거 3

#### 🎯 성공 지표
[어떻게 이 결정의 성공을 측정할 것인가?]

#### 🔄 재검토 조건
[어떤 상황에서 이 결정을 재검토할 것인가?]
```

---

## 🎯 결론

### ADR의 가치

1. **팀 정렬**: 모두가 같은 맥락 이해
2. **빠른 의사결정**: 과거 결정 참고
3. **실수 방지**: 이미 검토한 옵션 재논의 방지
4. **온보딩 가속**: 신규 팀원이 "왜?"를 이해

### 유지보수 원칙

- ✅ **모든 중요 결정 기록**: "이건 왜 이렇게 했지?"라는 질문이 나오면 ADR 필요
- ✅ **간결하게 작성**: 1-2페이지 권장
- ✅ **정기 검토**: 분기마다 재검토 조건 확인
- ✅ **수정 가능**: 상황 변화 시 상태 업데이트

---

**문서 버전**: v1.0  
**최종 수정**: 2026.02.06  
**다음 검토 예정**: 2026-05-06
